{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to install some libraries. Uncomment / edit relevant stuff (try to first run all the cells and then install missing libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install torch torchvision\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "# !{sys.executable} -m pip install imgaug\n",
    "# !{sys.executable} -m pip install albumentations\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    " \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "from os.path import join as pjoin\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "mpl.rcParams['figure.figsize'] = (15,8)\n",
    "mpl.rcParams['image.cmap'] = 'inferno'\n",
    " \n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = pjoin(ROOT_DIR, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '{DATA_DIR}'\n",
    "!curl --header 'Host: storage.googleapis.com' --user-agent 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:63.0) Gecko/20100101 Firefox/63.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --header 'Upgrade-Insecure-Requests: 1' 'https://storage.googleapis.com/kaggle-datasets/24658/194179/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1543686099&Signature=hwSthMO3LEr7oP1ni8wyWGusb3Qdj1%2FS94fn3bflvtbzfVXKAcd%2FtR8XFiP8pIrDhx79SLpDYGh57NLM7sb3Ea0LCkh9kFlW%2BnBXSo4jOTPDLcVZbe%2B54cp3%2Faddb1PM2%2Fq7W4pzsIV8i8hMsq2XeqU%2F%2BQcPvaiUfzaUU6xkpPQ6VeaQrW9h9XR3rYbjoJECn5KfKuV0pOHpHA%2Fbg6oyt57cOPuQ3PRS7HyLBMxZKY27pcM6rXJuUGTObr60G4Ywk3kp2JYDVGj6kIUA4bu%2BB%2FxefEPF6pgkjQo7T3SwLXpGhlJ8jBvULiXjUi0N3UC6REzWxzCKeGkvxky4YP7keg%3D%3D' --output '{DATA_DIR}/train.csv.zip'\n",
    "!curl --header 'Host: storage.googleapis.com' --user-agent 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:63.0) Gecko/20100101 Firefox/63.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --header 'Upgrade-Insecure-Requests: 1' 'https://storage.googleapis.com/kaggle-datasets/24658/194179/test.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1543686125&Signature=QI1fcdpPywTwQumWCIMsOz2JrVVx9ADvSf7JmnWcOLqGHVpnJKu%2FRasnoSHpuTb6jqcvnMM%2BZsl21%2FQLhIhp9fdE4%2BDBW2ZRTAnBDK1lz6NR6B4TJMQRAWogTNkJ9BkH6OeGOm%2FF%2F219%2BAWRKajkn3DL%2FBP5nynC%2B4RpBet4%2FRwGroMVuomjBpBE5eqC35f8nbRrnJNozVdBa8Ffy4RVm9Gu7fiK6zIKqIn%2Bc2LkXkhgcrT2nmwBBsriwcpv%2F%2FWBd4%2FeHV6sAE%2BIAcXEDOMQ4TQtYovXrhjDRe30SkjWlI8g79LQp%2FmOqAAe7yjjHb%2FO3XOiLExo3R2sPe8vwUUm%2Bw%3D%3D' --output '{DATA_DIR}/test.csv.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! Please unzip received files into the same directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_image_file_loader(path):\n",
    "#     return Image.open(path).convert('RGB')\n",
    "#     return plt.imread(path)\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def read_image(row, mode='url', datadir=DATA_DIR):\n",
    "    if mode == 'url':\n",
    "        return io.imread(row.url)\n",
    "    else:\n",
    "        return default_image_file_loader(pjoin(datadir, '{}.jpg'.format(row.id)))\n",
    "\n",
    "def look_at_random(df, n=5, mode='url', datadir=DATA_DIR,\n",
    "                   is_train=True, images_per_row=4, figsize=(20,10)):\n",
    "    mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "    datadir = pjoin(datadir, 'train') if is_train else pjoin(datadir, 'test')\n",
    "    df_size = len(df['id'].unique())\n",
    "    # make grid\n",
    "    num_cols = images_per_row\n",
    "    num_rows = (n - 1) // images_per_row + 1\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        ind = np.random.randint(0, df_size)\n",
    "        row = df.loc[ind]\n",
    "        try:\n",
    "            image = read_image(row, mode=mode, datadir=datadir)\n",
    "            landmark = int(row.landmark_id) if is_train else '?'\n",
    "            plt.subplot(num_rows, num_cols, i)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image)\n",
    "            plt.title('{}\\nclass: {}'.format(row.id, landmark))\n",
    "            i += 1\n",
    "        except:\n",
    "            pass\n",
    "    plt.show()\n",
    "\n",
    "def get_images_ids_from_class(landmark_id, df):\n",
    "    return list(df[df.landmark_id == landmark_id].id)\n",
    "            \n",
    "def look_at_randoms_from_class(df, landmark_id, n=5, mode='url', datadir=DATA_DIR,\n",
    "                               images_per_row=4, figsize=(20,10)):\n",
    "    mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "    images_ids = get_images_ids_from_class(landmark_id, df)\n",
    "    # make grid\n",
    "    num_cols = images_per_row\n",
    "    num_rows = (n - 1) // images_per_row + 1\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        img_id = np.random.choice(images_ids)\n",
    "        row = df[df.id == img_id].iloc[0]\n",
    "        try:\n",
    "            image = read_image(row, mode=mode, datadir=pjoin(datadir, 'train'))\n",
    "            plt.subplot(num_rows, num_cols, i)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image)\n",
    "            plt.title('{}\\nclass: {}'.format(img_id, landmark_id))\n",
    "            i += 1\n",
    "        except:\n",
    "            pass\n",
    "    plt.show()\n",
    "    \n",
    "def get_most_frequent_landmarks(df, top=5, n=5, mode='url', datadir=DATA_DIR,\n",
    "                                reverse=False, figsize=(20,10)):\n",
    "    \"\"\"List of the most/least frequent landmarks\n",
    "    \"\"\"\n",
    "    if reverse:\n",
    "        top_landmarks = pd.DataFrame(df.landmark_id.value_counts().tail(top))\n",
    "    else:\n",
    "        top_landmarks = pd.DataFrame(df.landmark_id.value_counts().head(top))\n",
    "    \n",
    "    top_landmarks.reset_index(inplace=True)\n",
    "    top_landmarks.columns = ['landmark_id', 'num']\n",
    "    plt.figure(figsize = figsize)\n",
    "    plt.title('Most frequent landmarks' if not reverse else \\\n",
    "              'Least frequent landmarks')\n",
    "    sns.set_color_codes(\"pastel\")\n",
    "    sns.barplot(x=\"landmark_id\", y=\"num\", data=top_landmarks,\n",
    "                label=\"Count\")\n",
    "    plt.show()\n",
    "    if n > 0:\n",
    "        for _, row in top_landmarks.iterrows():\n",
    "            print('\\n\\t{} images of class {}'.format(row.num, row.landmark_id))\n",
    "            look_at_randoms_from_class(df, row.landmark_id,\n",
    "                                       n=n, mode=mode, datadir=datadir,\n",
    "                                       images_per_row=4,\n",
    "                                       figsize=(20,10))\n",
    "            \n",
    "def get_random(df, n=5, mode='url', datadir=DATA_DIR, is_train=True):\n",
    "    datadir = pjoin(datadir, 'train') if is_train else pjoin(datadir, 'test')\n",
    "    df_size = len(df['id'].unique())\n",
    "    images, landmarks = [], []\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        ind = np.random.randint(0, df_size)\n",
    "        row = df.loc[ind]\n",
    "        try:\n",
    "            image = read_image(row, mode=mode, datadir=datadir)\n",
    "            landmark = int(row.landmark_id) if is_train else '?'\n",
    "            images.append(image)\n",
    "            landmarks.append(landmark)\n",
    "            i += 1\n",
    "        except:\n",
    "            pass\n",
    "    return images, landmarks\n",
    "\n",
    "def get_random_from_class(df, landmark_id, n=5, mode='url', datadir=DATA_DIR):\n",
    "    images = []\n",
    "    images_ids = get_images_ids_from_class(landmark_id, df)\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        img_id = np.random.choice(images_ids)\n",
    "        row = df[df.id == img_id].iloc[0]\n",
    "        try:\n",
    "            image = read_image(row, mode=mode, datadir=pjoin(datadir, 'train'))\n",
    "            images.append(image)\n",
    "            i += 1\n",
    "        except:\n",
    "            pass\n",
    "    return images, [landmark_id] * n\n",
    "\n",
    "def visualize_images(images, landmarks=None, images_per_row=4, figsize=(20,10)):\n",
    "    mpl.rcParams[\"figure.figsize\"] = figsize\n",
    "    # make grid\n",
    "    n = len(images)\n",
    "    num_cols = images_per_row\n",
    "    num_rows = (n - 1) // images_per_row + 1\n",
    "    i = 1\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(num_rows, num_cols, i+1)\n",
    "        plt.axis('off')\n",
    "        s = '\\nclass {}'.format(landmarks[i]) if landmarks is not None else ''\n",
    "        plt.title(str(image.shape[:2]) + s)\n",
    "        plt.imshow(image, cmap='gray' if image.ndim == 2 else None)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first stage we won't need all the images to be downloaded locally. We can analyse and preprocess data using only the dataframes. If you want to work with this dataset, it may be reasonable to first clean data and then download images that are relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'url' # may also be 'files' if you have image downloaded locally\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "train_size = len(train_df.id.unique())\n",
    "num_classes = len(train_df.landmark_id.unique())\n",
    "test_size = len(test_df.id.unique())\n",
    "print('{} train images from {} classes.'.format(train_size, num_classes))\n",
    "print('{} test images.'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get familiar with images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_at_random(train_df, n=5, mode=MODE, datadir=DATA_DIR, is_train=True,\n",
    "               images_per_row=5, figsize=(20,100))\n",
    "\n",
    "look_at_random(test_df, n=5, mode=MODE, datadir=DATA_DIR, is_train=False,\n",
    "               images_per_row=5, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_id = '0'\n",
    "look_at_randoms_from_class(train_df, landmark_id, mode=MODE, datadir=DATA_DIR,\n",
    "                           n=5, images_per_row=5, figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which landmarks are the most popular and how many examples are there, and also let's check the least popular classes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_most_frequent_landmarks(train_df, top=50, n=0, mode='url',\n",
    "                            datadir=DATA_DIR, figsize=(20,8))\n",
    "get_most_frequent_landmarks(train_df, top=50, n=0, reverse=True,\n",
    "                            datadir=DATA_DIR, figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some utility functions again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_quantile(x, p):\n",
    "    from math import floor\n",
    "    \"\"\"\n",
    "    0 <= p <= 1\n",
    "    \"\"\"\n",
    "    x = sorted(x)\n",
    "    n = len(x)\n",
    "    \n",
    "    m = n * p\n",
    "    if m % 1 == 0:\n",
    "        m = int(m)\n",
    "        return (x[m-1] + x[m]) / 2\n",
    "    else:\n",
    "        return x[int(floor(m))]\n",
    "\n",
    "def class_distr(train_df, bins, q=0.15):\n",
    "    stats = train_df.landmark_id.value_counts(ascending=True)\n",
    "    mean, lower_q, upper_q = stats.mean(), p_quantile(stats, q), p_quantile(stats, 1-q)\n",
    "    print('mean: {} images per class, lower {}%-quantile: {}, upper {}%-quantile: {}'.\\\n",
    "          format(mean, q*100, lower_q, q*100, upper_q))\n",
    "    values = []\n",
    "    for (x, y) in zip(bins[:-1], bins[1:]):\n",
    "        value = stats[stats <= y][stats > x].count()\n",
    "        print('{:5} < n <= {:<5}: {}'.format(x, y, value))\n",
    "        values.append(value)\n",
    "    plt.step(bins[:-1], values)\n",
    "    plt.vlines(mean, 0, max(values), 'gray', 'dashed')\n",
    "    plt.vlines(lower_q, 0, max(values), 'k', 'dashed')\n",
    "    plt.vlines(upper_q, 0, max(values), 'k', 'dashed')\n",
    "    plt.xlabel('Images in class')\n",
    "    plt.xlabel('Number of classes')\n",
    "    plt.show()\n",
    "\n",
    "def remove_outliers_landmarks(df, min_count=-np.inf, max_count=np.inf):\n",
    "    counts = df.landmark_id.value_counts()\n",
    "    landmarks_to_remove = list(counts[counts <= min_count].index) + \\\n",
    "                          list(counts[counts >= max_count].index)\n",
    "    print('Removed {} landmarks &'.format(len(landmarks_to_remove)))\n",
    "    print('        {} images'.format(len(df[df.landmark_id.isin(landmarks_to_remove)])))\n",
    "    new_df = df[~df.landmark_id.isin(landmarks_to_remove)]\n",
    "    print('Now we have {} images from {} classes.'.format(len(new_df.id.unique()),\n",
    "                                                          len(new_df.landmark_id.unique())))\n",
    "    return new_df\n",
    "\n",
    "def shorten_for_demo(df, max_num_landmarks=1000, max_count=np.inf):\n",
    "    print('\\nRandom choice for shortening...')\n",
    "    num_landmarks = len(df.landmark_id.unique())\n",
    "    if num_landmarks < max_num_landmarks:\n",
    "        landmarks_indices = np.arange(num_landmarks)\n",
    "    else:\n",
    "        landmarks_indices = np.random.choice(range(num_landmarks), max_num_landmarks, replace=False)\n",
    "    total_ids_to_save = []\n",
    "    for landmark_id, count in df.landmark_id.value_counts().iloc[landmarks_indices].iteritems():\n",
    "        landmark_images_ids = df[df.landmark_id == landmark_id].id\n",
    "        if count < max_count:\n",
    "            ids_to_save = list(landmark_images_ids)\n",
    "        else:\n",
    "            random_ids = np.random.choice(landmark_images_ids, max_count, replace=False)\n",
    "            ids_to_save = list(random_ids)\n",
    "        total_ids_to_save.extend(ids_to_save)\n",
    "    new_df = df[df.id.isin(total_ids_to_save)]\n",
    "    print('Now we have {} images'.format(len(new_df)))\n",
    "    print('            {} landmarks'.format(len(new_df.landmark_id.unique())))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obvious: remove landmarks with very few examples in class (say less then 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 10\n",
    "train_df_filtered = remove_outliers_landmarks(train_df, min_count=th)\n",
    "train_size = len(train_df_filtered.id.unique())\n",
    "num_classes = len(train_df_filtered.landmark_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the approximate distribution of the number of images in class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.1 # quantile to visualize for understanding\n",
    "bins = [0, 22, 50, 100, 199, 501, 1000, 1995, 5011, 10000]\n",
    "class_distr(train_df_filtered, bins, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have different goals regarding the dataset. But in many cases we need to make it balanced. So e.g. we can cut dataset such that only the classes of size between lower and upper 10% quantiles remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = train_df_filtered.landmark_id.value_counts(ascending=True)\n",
    "mean, lower_q, upper_q = stats.mean(), p_quantile(stats, q), p_quantile(stats, 1-q)\n",
    "train_short_df = remove_outliers_landmarks(train_df_filtered,\n",
    "                                           min_count=lower_q, max_count=upper_q)\n",
    "train_short_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the demonstration of image preprocessing we'll download 3 random classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_demo_df = shorten_for_demo(train_short_df, max_num_landmarks=3, max_count=upper_q)\n",
    "train_demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_DIR = pjoin(DATA_DIR, 'train')\n",
    "if not os.path.exists(TRAIN_DATA_DIR):\n",
    "    os.makedirs(TRAIN_DATA_DIR)\n",
    "    for i, row in train_demo_df.iterrows():\n",
    "        try:\n",
    "            filename, url, _ = row\n",
    "            urllib.request.urlretrieve(url, pjoin(TRAIN_DATA_DIR, '{}.jpg'.format(filename)))\n",
    "        except:\n",
    "            pass\n",
    "else:\n",
    "    train_demo_df = pd.read_csv(pjoin(DATA_DIR, 'train_demo.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the links become broken so we need to get rid of it. Because otherwise it may obstruct the process. We'll check whether there is a row in dataframe with no corresponding image in the local folder and remove it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_broken_links(df, img_dir):\n",
    "    return df.drop(df.index[[i for i, idx in enumerate(df.id.values)\n",
    "                    if not os.path.exists(pjoin(img_dir,'{}.jpg'.format(idx)))]])\n",
    "\n",
    "print('Number of examples train table has')\n",
    "print('\\tbefore cleaning: {}'.format(len(train_demo_df.index)))\n",
    "\n",
    "train_demo_df = remove_broken_links(train_demo_df, TRAIN_DATA_DIR)\n",
    "train_demo_df = train_demo_df.reset_index().drop(columns='index')\n",
    "train_demo_df.to_csv(pjoin(DATA_DIR, 'train_demo.csv'), index=False)\n",
    "\n",
    "print('\\tafter cleaning: {}'.format(len(train_demo_df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_demo_df.groupby(train_demo_df.landmark_id)[['id']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'file'\n",
    "landmarks = sorted(list(train_demo_df.landmark_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for landmark_id in landmarks:\n",
    "    look_at_randoms_from_class(train_demo_df, landmark_id, mode=MODE,\n",
    "                               datadir=DATA_DIR,\n",
    "                               n=5, images_per_row=5, figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's imagine that this data is all we have. We want to make it as representative as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentations | imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug.augmenters.size as iaas\n",
    "\n",
    "def get_augs():\n",
    "    iaa_Blur = iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 1.5)), # blur images with a sigma between 0 and 1.5\n",
    "                    iaa.AverageBlur(k=(2, 4)),  # blur image using local means with kernel sizes between 2 and 7\n",
    "                    iaa.MedianBlur(k=(3, 5)),   # blur image using local medians with kernel sizes between 3 and 5\n",
    "    ])\n",
    "    iaa_Sharpen = iaa.OneOf([\n",
    "                    iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5)), # sharpen images\n",
    "                    iaa.Emboss(alpha=(0, 0.5), strength=(0, 0.5)),      # emboss images\n",
    "    ])\n",
    "    iaa_Noise = iaa.OneOf([\n",
    "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.03*255), per_channel=0.1), # add gaussian noise to images\n",
    "                    iaa.Dropout((0, 0.02), per_channel=0.1), # randomly remove up to 10% of the pixels\n",
    "    ])\n",
    "    iaa_Affine = iaa.OneOf([\n",
    "                    iaa.Affine(\n",
    "                        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},               # scale images to 80-120% of their size (per axis)\n",
    "                        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "                        rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "                        shear=(-10, 10),  # shear by -10 to +10 degrees\n",
    "                        order=[0, 1],     # use nearest neighbour or bilinear interpolation (fast)\n",
    "                        cval=(0),\n",
    "                        mode='constant'   # use zeros for padding\n",
    "                    ),\n",
    "#                     iaa.PerspectiveTransform(scale=(0.01, 0.1)) # this is a very slow transformation\n",
    "    ])\n",
    "    iaa_HSV = iaa.SomeOf((0,4),[\n",
    "                    iaa.Grayscale(alpha=(0.0, 0.5)),  \n",
    "                    iaa.Add((-10, 10), per_channel=0.01), # change brightness of images (by -10 to 10 of original value)\n",
    "                    iaa.AddToHueAndSaturation((-10, 10)), # change hue and saturation\n",
    "                    iaa.Sequential([\n",
    "                       iaa.ChangeColorspace(from_colorspace=\"RGB\",  # additioinally change saturation\n",
    "                                            to_colorspace=\"HSV\"),\n",
    "                       iaa.WithChannels(1, iaa.Add((-100, 80))),\n",
    "                       iaa.ChangeColorspace(from_colorspace=\"HSV\",\n",
    "                                            to_colorspace=\"RGB\")\n",
    "                    ]),\n",
    "                    iaa.ContrastNormalization((0.7, 1.6), per_channel=0), # improve or worsen the contrast\n",
    "                    iaa.Multiply((0.7, 1.2), per_channel=0.01),    # change value\n",
    "                    iaa.FrequencyNoiseAlpha(                       # similar to previous ones\n",
    "                        exponent=(-2, 2),\n",
    "                        first=iaa.Multiply((0.85, 1.2), per_channel=False),\n",
    "                        second=iaa.ContrastNormalization((0.5, 1.7))),\n",
    "    ])\n",
    "    iaa_Simple = iaa.SomeOf((0,2), [\n",
    "                iaa.Fliplr(0.5),     # horizontally flip 50% of all images\n",
    "                iaa.CropAndPad(      # crop\n",
    "                    percent=(-0.05, 0.1),\n",
    "                    pad_mode='constant',\n",
    "                    pad_cval=(0)\n",
    "                ),\n",
    "    ])\n",
    "        \n",
    "    augs = {\n",
    "        'simple': iaa_Simple,\n",
    "        'affine': iaa_Affine,\n",
    "        'hsv': iaa_HSV,\n",
    "        'sharpen': iaa_Sharpen,\n",
    "        'blur': iaa_Blur,\n",
    "        'noise': iaa_Noise,\n",
    "    }\n",
    "    return augs\n",
    "\n",
    "def get_final_transform():\n",
    "    return iaa.Sequential([iaa.Crop(percent=(0,0.2), keep_size=False),\n",
    "                           iaa.Scale({\"height\": 512, \"width\": \"keep-aspect-ratio\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.figsize\"] = (20, 20)\n",
    "augs = get_augs()\n",
    "final = get_final_transform()\n",
    "augs_keys = list(augs.keys())\n",
    "print('So we have: {}'.format(augs_keys))\n",
    "landmark_id = landmarks[0]\n",
    "imgs, _ = get_random_from_class(train_demo_df, landmark_id, mode=MODE,\n",
    "                                datadir=DATA_DIR, n=len(augs_keys))\n",
    "imgs = [np.array(img) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(augs_keys)):\n",
    "    print(augs_keys[i])\n",
    "    img = imgs[i]\n",
    "    grid = iaa.Sequential([augs[augs_keys[i]], final]).draw_grid([img], cols=4, rows=2)\n",
    "    plt.imshow(grid.astype(np.uint8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(get_random_from_class(train_demo_df, landmark_id, mode=MODE, datadir=DATA_DIR, n=1)[0][0])\n",
    "total_augs = iaa.Sequential([augs['hsv'],\n",
    "                             iaa.OneOf([augs['sharpen'], augs['blur'], augs['noise']]),\n",
    "                             iaa.SomeOf((0,2), [augs['affine'], augs['simple']])])\n",
    "grid = iaa.Sequential([total_augs, final]).draw_grid([img], cols=4, rows=4)\n",
    "plt.imshow(grid.astype(np.uint8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentations | torch & torchvision <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor : Tensor\n",
    "            Tensor image of size (C, H, W) to be normalized.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            Unnormalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "class SquareCenterCrop(object):\n",
    "    \"\"\"Crops the given PIL Image as a square at the center to save maximum.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        img : PIL Image\n",
    "            Image to be cropped.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        PIL Image\n",
    "            Cropped image.\n",
    "        \"\"\"\n",
    "        h, w = img.size\n",
    "        size = min(h, w)\n",
    "        size = (int(size), int(size))\n",
    "        return F.center_crop(img, size)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(size={0})'.format(self.size)\n",
    "    \n",
    "class LandmarksTransforms():\n",
    "    CENTER_CROP_SHAPE = [1024, 1024]\n",
    "    FINAL_SIZE = 224\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "    BRIGTHNESS = 0.5\n",
    "    CONTRAST = 0.5\n",
    "    SATURATION = 0.3\n",
    "    HUE = 0.05\n",
    "    SCALES = (0.08, 1.0)\n",
    "    RATIOS = (0.8, 1.2)\n",
    "    \n",
    "    def __init__(self, mean=None, std=None):\n",
    "        if mean is not None:\n",
    "            self.MEAN = mean\n",
    "        if mean is not None:\n",
    "            self.STD = std\n",
    "        self.augment = transforms.Compose([\n",
    "                            SquareCenterCrop(),\n",
    "                            transforms.RandomResizedCrop(self.FINAL_SIZE,\n",
    "                                                         self.SCALES, self.RATIOS),\n",
    "                            transforms.RandomHorizontalFlip(),\n",
    "                            transforms.ColorJitter(self.BRIGTHNESS, self.CONTRAST,\n",
    "                                                   self.SATURATION, self.HUE)\n",
    "                        ])\n",
    "#         self.augment = iaa.Sequential([total_augs, final])\n",
    "        self.justResize = transforms.Compose([\n",
    "            SquareCenterCrop(),\n",
    "            transforms.Resize(self.FINAL_SIZE)\n",
    "        ])\n",
    "        self.toTensor = transforms.ToTensor()\n",
    "        self.normalize = transforms.Normalize(self.MEAN, self.STD)\n",
    "        self.unnormalize = UnNormalize(self.MEAN, self.STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_image_file_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "class LandmarksDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, images_dir,\n",
    "                 is_train=True, augment=True, name=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe: pd.DataFrame or str\n",
    "            csv table (or path to it) with following columns:\n",
    "                id : str\n",
    "                    id and also it's an image .jpg file name in images_dir\n",
    "                url : str\n",
    "                    link to image\n",
    "                landmark_id : str\n",
    "                    class [if is_train == True]\n",
    "        images_dir: str\n",
    "            path to directory containing images\n",
    "        is_train: bool\n",
    "            flag defining whether the classes are provided in table\n",
    "        augment: bool\n",
    "            flag defining whether to apply augmentation transformations on images\n",
    "        name: str\n",
    "            just the name of dataset\n",
    "        \"\"\"\n",
    "        if isinstance(dataframe, pd.DataFrame):\n",
    "            self.df = dataframe\n",
    "        elif isinstance(dataframe, str):\n",
    "            self.df = pd.read_csv(dataframe)\n",
    "        self.is_train = is_train\n",
    "        self.augment = augment\n",
    "        self.name = name\n",
    "        \n",
    "        assert set(['id', 'url']).issubset(set(self.df.columns)), \\\n",
    "             'Please, provide DataFrame with `id` and `url`'\n",
    "        self.images_ids = self.df.id.values\n",
    "        self.images_paths = list(map(lambda id: os.path.join(images_dir, '{}.jpg'.format(id)),\n",
    "                                     self.images_ids))\n",
    "        self.images_urls = self.df.url.values\n",
    "        self.num_samples = len(self.images_ids)\n",
    "        print('Dataset {} loaded'.format(\"'\"+self.name+\"'\" if self.name is not None else ''))\n",
    "        print('\\t{} images'.format(self.num_samples))\n",
    "        \n",
    "        if self.is_train:\n",
    "            assert 'landmark_id' in self.df, 'Please, provide DataFrame with `landmark_id`'\n",
    "            self.classes_ids = self.df.landmark_id.values\n",
    "            self.num_classes = len(set(self.classes_ids))\n",
    "            self.class_mapping = dict(zip(set(self.classes_ids), range(self.num_classes)))\n",
    "            self.classes = [self.class_mapping[cl] for cl in self.classes_ids]\n",
    "            print('\\t{} classes'.format(self.num_classes))\n",
    "        else:\n",
    "            print('\\tclasses are not provided')\n",
    "            \n",
    "        self.image_loader = default_image_file_loader\n",
    "        self.transforms = LandmarksTransforms()\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):    \n",
    "        image_id = self.images_ids[index]\n",
    "        image = self.image_loader(self.images_paths[index])\n",
    "        if self.is_train and self.augment:\n",
    "            image = self.transforms.augment(image)\n",
    "        else:\n",
    "            image = self.transforms.justResize(image)\n",
    "        image = self.transforms.toTensor(image)\n",
    "        image = self.transforms.normalize(image)\n",
    "        if self.is_train:\n",
    "            class_id = self.classes[index]\n",
    "            return image_id, image, class_id\n",
    "        else:\n",
    "            return image_id, image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_paths)\n",
    "    \n",
    "    def stats(self):\n",
    "        shapes = [cv2.imread(img_path).shape for img_path in self.images_paths]\n",
    "        return shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LandmarksDataset(train_demo_df, TRAIN_DATA_DIR,\n",
    "                           is_train=True, augment=True, name='landmarks')\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 16\n",
    "loader = DataLoader(dataset, shuffle=True,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (_, inputs, targets) in loader:\n",
    "    for i, (img, cls) in enumerate(zip(inputs, targets)):\n",
    "        img = dataset.transforms.unnormalize(img).numpy().transpose(1,2,0)\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        plt.axis('off')\n",
    "        plt.title(cls.item())\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
